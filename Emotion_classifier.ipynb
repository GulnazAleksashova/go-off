{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion_classifier",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GulnazAleksashova/go-off/blob/main/Emotion_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdm4Dtpo88RB"
      },
      "source": [
        "# Emotion classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWiCMHe2LPU4"
      },
      "source": [
        "import os \n",
        "import shutil\n",
        "import librosa \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import time\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import concatenate, Input, Dense, Dropout, \\\n",
        "                                    BatchNormalization, Flatten, Conv1D, Conv2D, LSTM \n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDvFcj3CjnxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b9f5751-3e3f-415e-c8d2-bebbed018c8d"
      },
      "source": [
        "# The library for working with google disk\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw-k-4N66E4J"
      },
      "source": [
        "# Unzip the source database into the Google Colaboratory\n",
        "!unzip -q '/content/drive/MyDrive/Базы/Emotion.zip' #распаковываем исходную базу в ноутбук колаба"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRfteKXqScPR",
        "outputId": "2c2cfdde-bc7d-4393-92d1-e64b5c0c09c2"
      },
      "source": [
        "# Content of the source directory <TESS Toronto emotional speech set data>\n",
        "!ls TESS\\ Toronto\\ emotional\\ speech\\ set\\ data # \\ - escapes spaces\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OAF_angry    OAF_neutral\t    YAF_disgust  YAF_pleasant_surprised\n",
            "OAF_disgust  OAF_Pleasant_surprise  YAF_fear\t YAF_sad\n",
            "OAF_Fear     OAF_Sad\t\t    YAF_happy\n",
            "OAF_happy    YAF_angry\t\t    YAF_neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHRk9XSwLIQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6458b0-9b1f-4f5c-f3f1-8c625df4030d"
      },
      "source": [
        "# The list of all paths to existing files in the TESS folder\n",
        "path = '/content/TESS Toronto emotional speech set data'\n",
        "spisok = [] \n",
        "for adress, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "        spisok.append(os.path.join(adress,file))\n",
        "print(len(spisok))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Rz8HGe1b2u"
      },
      "source": [
        "# Tranformation of the data set\n",
        "# Create an empty emotion folder with 7 empty folders for each emotion\n",
        "path = '/content'\n",
        "dirname = 'emotion'\n",
        "folders = ['fear', \n",
        "           'pleasant_surprise',\n",
        "           'sad', \n",
        "           'angry', \n",
        "           'disgust', \n",
        "           'happy', \n",
        "           'neutral']\n",
        "\n",
        "def createFolder(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)\n",
        "\n",
        "fullPath = os.path.join(path,dirname)\n",
        "createFolder(fullPath)\n",
        "for f in folders:\n",
        "    folder = os.path.join(fullPath,f)\n",
        "    createFolder(folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AMhgd4a8DW9"
      },
      "source": [
        "# Path way to each emotion\n",
        "path_angry = '/content/emotion/angry'\n",
        "path_disgust = '/content/emotion/disgust'\n",
        "path_fear = '/content/emotion/fear'\n",
        "path_happy = '/content/emotion/happy'\n",
        "path_neutral = '/content/emotion/neutral'\n",
        "path_pleasant_surprise = '/content/emotion/pleasant_surprise'\n",
        "path_sad = '/content/emotion/sad'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzVOn0oIQ8L0"
      },
      "source": [
        "# Distribution of emotion audio files according to classes\n",
        "for i in range(len(spisok)):\n",
        "    path = spisok[i]\n",
        "    if path.endswith('_angry.wav'):\n",
        "        shutil.copy(path,path_angry)\n",
        "    if path.endswith('_disgust.wav'):\n",
        "        shutil.copy(path,path_disgust)\n",
        "    if path.endswith('_fear.wav'):\n",
        "        shutil.copy(path,path_fear)\n",
        "    if path.endswith('_happy.wav'):\n",
        "        shutil.copy(path,path_happy)\n",
        "    if path.endswith('_neutral.wav'):\n",
        "        shutil.copy(path,path_neutral)\n",
        "    if path.endswith('_ps.wav'):\n",
        "        shutil.copy(path,path_pleasant_surprise)\n",
        "    if path.endswith('_sad.wav'):\n",
        "        shutil.copy(path,path_sad) \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbsB6VcrxfXW",
        "outputId": "aa4fa6b0-85fc-44e2-f4d2-f70ae17f69c2"
      },
      "source": [
        "# Example of counting number of files for current emotion\n",
        "path, dirs, files = next(os.walk('/content/emotion/angry'))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8FpsSAYyjtV"
      },
      "source": [
        "# Function of get features\n",
        "def get_features(y, sr):\n",
        "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr) # Chroma frequency (default 12 color tanks)\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr) # Mel-frequency cepstral coefficients (default 20)\n",
        "  \n",
        "    rmse = np.mean(librosa.feature.rms(y=y)) # Mean of root-mean-square (RMS) value for each frame\n",
        "    spec_cent = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)) # Mean of spectral centroid\n",
        "    spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)) # Mean of spectral bandwidth\n",
        "    rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)) # Mean of roll-off frequency\n",
        "    zcr = np.mean(librosa.feature.zero_crossing_rate(y)) # Mean of zero-crossing rate of an audio time series\n",
        "  \n",
        "  \n",
        "    # An empty list of audio parameters\n",
        "    out = []  \n",
        "    out.append(rmse) \n",
        "    out.append(spec_cent) \n",
        "    out.append(spec_bw) \n",
        "    out.append(rolloff) \n",
        "    out.append(zcr)  \n",
        "  \n",
        "    # Mean of all Mel-frequency cepstral coefficients (20 values)\n",
        "    for e in mfcc:\n",
        "        out.append(np.mean(e))\n",
        "\n",
        "    # Mean of all Chroma frequency (12 values)\n",
        "    for e in chroma_stft:\n",
        "        out.append(np.mean(e))\n",
        "  \n",
        "    # List of parameters with dimension (37,)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8enh7HU5QPp"
      },
      "source": [
        "emotion = os.listdir('emotion')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vkodOL2M20p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1230e08b-c94b-458c-ada3-19d8c72f07e0"
      },
      "source": [
        "# Create a training set\n",
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "# Training set creation start time\n",
        "curr_time = time.time()\n",
        "\n",
        "\n",
        "for i in range(len(emotion)):\n",
        "    e = emotion[i] # For each emotion\n",
        "    for filename in os.listdir(f'./emotion/{e}'):\n",
        "        # Get name of a file\n",
        "        emotionName = f'./emotion/{e}/{filename}'\n",
        "        # Use first 30 seconds of audio\n",
        "        y, sr = librosa.load(emotionName, mono=True, duration=30) # y - audio time series dataset, \n",
        "                                                                  # sr - audio sample rate\n",
        "        # Get parameters for training model\n",
        "        out = get_features(y, sr)\n",
        "    \n",
        "        # X_train\n",
        "        X_train.append(out)\n",
        "        # Y_train in ohe format\n",
        "        Y_train.append(to_categorical(i, len(emotion)))\n",
        "\n",
        "    # Information about the readiness of database processing\n",
        "    print('Emotion ', e, \" is ready -> \", round(time.time() - curr_time), \"sec\", sep=\" \")\n",
        "    curr_time = time.time()\n",
        "\n",
        "# Converting training set to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion  fear  is ready ->  40 sec\n",
            "Emotion  neutral  is ready ->  48 sec\n",
            "Emotion  sad  is ready ->  54 sec\n",
            "Emotion  happy  is ready ->  46 sec\n",
            "Emotion  disgust  is ready ->  55 sec\n",
            "Emotion  pleasant_surprise  is ready ->  47 sec\n",
            "Emotion  angry  is ready ->  44 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHCTyx4pWdIb"
      },
      "source": [
        "# Create backup of training set\n",
        "X_train_backup = X_train.copy()\n",
        "Y_train_backup = Y_train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSop5ieuS8bB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "105aa485-cc8c-46f0-889a-d7b2756e0a16"
      },
      "source": [
        "# Number of classes\n",
        "y_train_class = np.argmax(Y_train, axis=1)\n",
        "print(y_train_class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 6 6 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPB2A_HOSl-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b84ac09-7b16-429c-85d5-82c31673a92b"
      },
      "source": [
        "# Shape of the training set\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(y_train_class.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2800, 37)\n",
            "(2800, 7)\n",
            "(2800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ1-UoWUNcTL"
      },
      "source": [
        "# Normalization of training set data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpi_4EfswvE2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0857dd5f-ed74-4442-f9f8-ce195cf6461e"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.8138658   0.97365577  0.69244905  1.09360828  0.86253233  1.21936581\n",
            " -1.18607546 -1.39501369  0.76695095 -0.05291146 -0.40782365  0.27760923\n",
            "  0.18008068 -0.74673401  0.57222089 -1.24486336 -0.14151916  1.03637773\n",
            " -1.35638962  0.55285374 -1.16238667 -0.80780705  1.70566379  0.22128142\n",
            "  2.08989465  0.37427367 -0.37409173 -0.46103319 -0.47426506  0.7950521\n",
            " -0.21002796 -0.14810765 -0.00418789 -1.20099565 -1.23264485 -0.94619222\n",
            "  0.30411963]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSdgnnI_Sxir"
      },
      "source": [
        "# Split set to training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train_class, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up_RzaPSNfVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ff743e-2836-49fa-9eed-d4c112b4fdc9"
      },
      "source": [
        "# Shape of training and test sets\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2520, 37)\n",
            "(2520,)\n",
            "(280, 37)\n",
            "(280,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqpWVEbDNe2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac919ffb-de72-43dc-cc10-50b952a7515d"
      },
      "source": [
        "# An architecture of neural network\n",
        "# Indexes of input data\n",
        "indexes = range(0,37)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1000, activation='elu', input_shape=(len(indexes),)))\n",
        "model.add(Dense(750, activation='elu'))\n",
        "model.add(Dense(500, activation='elu'))\n",
        "model.add(Dense(250, activation='elu'))\n",
        "model.add(Dense(50, activation='elu'))\n",
        "\n",
        "model.add(Dense(len(emotion), activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train[:, indexes],\n",
        "                    y_train,\n",
        "                    epochs=200,\n",
        "                    batch_size=20,\n",
        "                    validation_data=(X_test[:, indexes], y_test))\n",
        "\n",
        "# Visualization of training process\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "126/126 [==============================] - 3s 17ms/step - loss: 0.2584 - accuracy: 0.9345 - val_loss: 0.0790 - val_accuracy: 0.9821\n",
            "Epoch 2/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0500 - accuracy: 0.9865 - val_loss: 0.0371 - val_accuracy: 0.9929\n",
            "Epoch 3/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0266 - accuracy: 0.9944 - val_loss: 0.0305 - val_accuracy: 0.9893\n",
            "Epoch 4/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.0169 - val_accuracy: 0.9929\n",
            "Epoch 5/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0141 - accuracy: 0.9948 - val_loss: 0.0120 - val_accuracy: 0.9964\n",
            "Epoch 6/200\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0203 - val_accuracy: 0.9893\n",
            "Epoch 7/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0094 - val_accuracy: 0.9964\n",
            "Epoch 8/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0104 - val_accuracy: 0.9964\n",
            "Epoch 9/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.0169 - val_accuracy: 0.9929\n",
            "Epoch 10/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0148 - val_accuracy: 0.9929\n",
            "Epoch 11/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0072 - val_accuracy: 0.9964\n",
            "Epoch 14/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0281 - val_accuracy: 0.9929\n",
            "Epoch 15/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.0096 - val_accuracy: 0.9929\n",
            "Epoch 16/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 8.3924e-04 - accuracy: 0.9996 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
            "Epoch 17/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.1414e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9964\n",
            "Epoch 18/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.2099e-04 - accuracy: 0.9996 - val_loss: 0.0109 - val_accuracy: 0.9964\n",
            "Epoch 19/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9964\n",
            "Epoch 20/200\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 5.5541e-04 - accuracy: 0.9996 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0150 - val_accuracy: 0.9964\n",
            "Epoch 22/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.1878e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.6965e-05 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9964\n",
            "Epoch 24/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.9032e-04 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9929\n",
            "Epoch 25/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7309e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9964\n",
            "Epoch 26/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.1552e-06 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 0.9964\n",
            "Epoch 27/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.3797e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9893\n",
            "Epoch 28/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.1866e-05 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9964\n",
            "Epoch 29/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.1651e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.6532e-06 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9964\n",
            "Epoch 31/200\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 4.9780e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.4127e-06 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9964\n",
            "Epoch 33/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 8.3680e-07 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9964\n",
            "Epoch 34/200\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 2.5668e-04 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9929\n",
            "Epoch 35/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.3340e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.1064e-07 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9964\n",
            "Epoch 37/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 8.1554e-08 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9964\n",
            "Epoch 38/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.1807e-07 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 0.9964\n",
            "Epoch 39/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.4211e-08 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9929\n",
            "Epoch 40/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.6983e-08 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9964\n",
            "Epoch 41/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.1684e-08 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9964\n",
            "Epoch 42/200\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 1.0454e-08 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 0.9929\n",
            "Epoch 43/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 8.8461e-09 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9964\n",
            "Epoch 44/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 8.1838e-09 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9964\n",
            "Epoch 45/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.7173e-09 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9964\n",
            "Epoch 46/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.3389e-09 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 0.9964\n",
            "Epoch 47/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.9605e-09 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9964\n",
            "Epoch 48/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.5347e-09 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9964\n",
            "Epoch 49/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.0144e-09 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9929\n",
            "Epoch 50/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.5413e-09 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9929\n",
            "Epoch 51/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.1156e-09 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9929\n",
            "Epoch 52/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.5952e-09 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9929\n",
            "Epoch 53/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.5006e-09 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9929\n",
            "Epoch 54/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.3587e-09 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9929\n",
            "Epoch 55/200\n",
            "126/126 [==============================] - 2s 15ms/step - loss: 3.0275e-09 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9929\n",
            "Epoch 56/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.0275e-09 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9929\n",
            "Epoch 57/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.7437e-09 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9929\n",
            "Epoch 58/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.7910e-09 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9929\n",
            "Epoch 59/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.5072e-09 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9929\n",
            "Epoch 60/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.4126e-09 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9929\n",
            "Epoch 61/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.3653e-09 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9929\n",
            "Epoch 62/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.5072e-09 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9929\n",
            "Epoch 63/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.0814e-09 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9929\n",
            "Epoch 64/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.2233e-09 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9929\n",
            "Epoch 65/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.8922e-09 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9964\n",
            "Epoch 66/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.8449e-09 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9929\n",
            "Epoch 67/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.8922e-09 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9964\n",
            "Epoch 68/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.7503e-09 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9964\n",
            "Epoch 69/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.7030e-09 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9929\n",
            "Epoch 70/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.7030e-09 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9929\n",
            "Epoch 71/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.5138e-09 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9929\n",
            "Epoch 72/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.3719e-09 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9929\n",
            "Epoch 73/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.3245e-09 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9929\n",
            "Epoch 74/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.1353e-09 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9929\n",
            "Epoch 75/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.2299e-09 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9929\n",
            "Epoch 76/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.2299e-09 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9929\n",
            "Epoch 77/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.1353e-09 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9929\n",
            "Epoch 78/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 9.4611e-10 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9929\n",
            "Epoch 79/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.1353e-09 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9929\n",
            "Epoch 80/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.0407e-09 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9964\n",
            "Epoch 81/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 9.4611e-10 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9929\n",
            "Epoch 82/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 9.4611e-10 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9929\n",
            "Epoch 83/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.0407e-09 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9929\n",
            "Epoch 84/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 8.5149e-10 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9929\n",
            "Epoch 85/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.0407e-09 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9964\n",
            "Epoch 86/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 9.4611e-10 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9964\n",
            "Epoch 87/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 7.0958e-10 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9929\n",
            "Epoch 88/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.6766e-10 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9929\n",
            "Epoch 89/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9929\n",
            "Epoch 90/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 8.0419e-10 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9929\n",
            "Epoch 91/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 7.5688e-10 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9964\n",
            "Epoch 92/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9929\n",
            "Epoch 93/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9964\n",
            "Epoch 94/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9964\n",
            "Epoch 95/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 7.5688e-10 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9929\n",
            "Epoch 96/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9964\n",
            "Epoch 97/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9929\n",
            "Epoch 98/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9964\n",
            "Epoch 99/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9964\n",
            "Epoch 100/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 8.0419e-10 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9964\n",
            "Epoch 101/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9964\n",
            "Epoch 102/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9964\n",
            "Epoch 103/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.6766e-10 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9929\n",
            "Epoch 104/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9964\n",
            "Epoch 105/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 7.5688e-10 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9964\n",
            "Epoch 106/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9929\n",
            "Epoch 107/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9964\n",
            "Epoch 108/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.6227e-10 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9964\n",
            "Epoch 109/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 5.6766e-10 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9964\n",
            "Epoch 110/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9964\n",
            "Epoch 111/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9929\n",
            "Epoch 112/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9964\n",
            "Epoch 113/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 5.6766e-10 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9964\n",
            "Epoch 114/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9964\n",
            "Epoch 115/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9964\n",
            "Epoch 116/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9964\n",
            "Epoch 117/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9964\n",
            "Epoch 118/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9964\n",
            "Epoch 119/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9964\n",
            "Epoch 120/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9964\n",
            "Epoch 121/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9964\n",
            "Epoch 122/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.6766e-10 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9964\n",
            "Epoch 123/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9964\n",
            "Epoch 124/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9964\n",
            "Epoch 125/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9964\n",
            "Epoch 126/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.6766e-10 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9964\n",
            "Epoch 127/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9964\n",
            "Epoch 128/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9964\n",
            "Epoch 129/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9964\n",
            "Epoch 130/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9964\n",
            "Epoch 131/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9964\n",
            "Epoch 132/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9964\n",
            "Epoch 133/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 134/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9964\n",
            "Epoch 135/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9964\n",
            "Epoch 136/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9964\n",
            "Epoch 137/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9964\n",
            "Epoch 138/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9964\n",
            "Epoch 139/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 140/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 141/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 142/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9964\n",
            "Epoch 143/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
            "Epoch 144/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
            "Epoch 145/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
            "Epoch 146/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
            "Epoch 147/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9964\n",
            "Epoch 148/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9964\n",
            "Epoch 149/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9964\n",
            "Epoch 150/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
            "Epoch 151/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 152/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.8922e-10 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9964\n",
            "Epoch 153/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 154/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 155/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
            "Epoch 156/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 157/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 6.1497e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 158/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9964\n",
            "Epoch 159/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9964\n",
            "Epoch 160/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 0.9964\n",
            "Epoch 161/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.3653e-10 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9964\n",
            "Epoch 162/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
            "Epoch 163/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9964\n",
            "Epoch 164/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
            "Epoch 165/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
            "Epoch 166/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
            "Epoch 167/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9964\n",
            "Epoch 168/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9964\n",
            "Epoch 169/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9964\n",
            "Epoch 170/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
            "Epoch 171/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9964\n",
            "Epoch 172/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.3653e-10 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9964\n",
            "Epoch 173/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9964\n",
            "Epoch 174/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.3653e-10 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9964\n",
            "Epoch 175/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 0.9964\n",
            "Epoch 176/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9964\n",
            "Epoch 177/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 0.9964\n",
            "Epoch 178/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9964\n",
            "Epoch 179/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9964\n",
            "Epoch 180/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9964\n",
            "Epoch 181/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9964\n",
            "Epoch 182/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9964\n",
            "Epoch 183/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9964\n",
            "Epoch 184/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 1.8922e-10 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9964\n",
            "Epoch 185/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9964\n",
            "Epoch 186/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.7844e-10 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9964\n",
            "Epoch 187/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9964\n",
            "Epoch 188/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9964\n",
            "Epoch 189/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 5.2036e-10 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9964\n",
            "Epoch 190/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.3653e-10 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9964\n",
            "Epoch 191/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 1.8922e-10 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9964\n",
            "Epoch 192/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.7305e-10 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 0.9964\n",
            "Epoch 193/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 0.9964\n",
            "Epoch 194/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.3653e-10 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9964\n",
            "Epoch 195/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 9.4611e-11 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9964\n",
            "Epoch 196/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.3653e-10 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9964\n",
            "Epoch 197/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 2.8383e-10 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9964\n",
            "Epoch 198/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9964\n",
            "Epoch 199/200\n",
            "126/126 [==============================] - 2s 16ms/step - loss: 3.3114e-10 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 0.9964\n",
            "Epoch 200/200\n",
            "126/126 [==============================] - 2s 17ms/step - loss: 4.2575e-10 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 0.9964\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6vzuZgS1ZY_"
      },
      "source": [
        "# Emotion recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrjwExW_zm4Y"
      },
      "source": [
        "# Choose audio file for recognition\n",
        "emotionName = './emotion/disgust/OAF_bath_disgust.wav'\n",
        "# An audio signal\n",
        "y, sr = librosa.load(emotionName, mono=True, duration=30)\n",
        "# Get parameters for training\n",
        "out = get_features(y, sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Fh1Oi20G57"
      },
      "source": [
        "#Add dimension\n",
        "out = np.array(out).reshape(1,37)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hjfpDdQ0NvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93323b9-1b0e-4eac-e2cd-05c81d36e867"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC5GUOqNz2oP"
      },
      "source": [
        "# Normalization of an audio signal\n",
        "out = scaler.transform(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTkzLF9T0k54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff84d7fd-ab4c-4253-e37d-80e16824853e"
      },
      "source": [
        "# Print normalized vector of an audio signal parameters\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.78812167 -0.8804883  -0.63740302 -1.09833144 -0.7801011  -0.58608994\n",
            "   1.18663211 -0.22687767 -1.24541541  1.49711351  0.7998436  -0.57327838\n",
            "   1.5406303  -0.23039576  1.28751113  0.99405709 -0.00942911  0.7238642\n",
            "  -0.23132915  0.62477886  1.25249576 -1.35984261 -0.01627598  0.56938522\n",
            "  -0.70297919  0.8243902   0.21228304  0.23189011  0.68515429  1.70354949\n",
            "   1.31561082 -0.05419634  0.06265963  0.72902043  0.5288528   0.45284728\n",
            "   1.33297293]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4DVb1S70skX"
      },
      "source": [
        "# Prediction\n",
        "y = model.predict(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoAhQedh1K9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21a9f7d-c7c1-4109-8d60-2300391df488"
      },
      "source": [
        "# Print results of prediction\n",
        "print('Result of prediction', y)\n",
        "print('Index of predicted class of emotion', np.argmax(y))\n",
        "print('Actual index of current emotion', emotion.index('disgust'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of prediction [[1.2162045e-17 6.2462285e-15 8.7206955e-15 1.7915042e-26 1.0000000e+00\n",
            "  1.2239111e-18 7.0387549e-15]]\n",
            "Index of predicted class of emotion 4\n",
            "Actual index of current emotion 4\n"
          ]
        }
      ]
    }
  ]
}